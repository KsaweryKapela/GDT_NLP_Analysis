{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from helpers import open_and_prepare_df, X_y_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X_y_split(open_and_prepare_df('features'), 'nlp_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_results(regression_function, X, y):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=8)\n",
    "\n",
    "    true_y = []\n",
    "    preds = []\n",
    "\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        regression_function.fit(X_train, y_train)\n",
    "        pred = regression_function.predict(X_test)\n",
    "        preds = np.concatenate((preds, pred))\n",
    "\n",
    "        true_y = np.concatenate((true_y, y_test))\n",
    "\n",
    "    corr = round(stats.pearsonr(preds, true_y)[0], 3)\n",
    "    mae = round(mean_absolute_error(preds, true_y), 3)\n",
    "\n",
    "    print(f'Corr = {corr}, MAE = {mae} Func: {regression_function}')\n",
    "\n",
    "    return corr, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [svm.SVR(kernel='linear', C=0.0255, tol=1e-3),\n",
    "            svm.LinearSVR(tol=1e-3, C=0.0255),\n",
    "            LinearRegression(),\n",
    "            Ridge(alpha=200),\n",
    "            RandomForestRegressor(max_depth=24),\n",
    "            MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam'),\n",
    "            KNeighborsRegressor(n_neighbors=10),\n",
    "            DecisionTreeRegressor(max_depth=10),\n",
    "            GradientBoostingRegressor(n_estimators=100, max_depth=5),\n",
    "            GaussianProcessRegressor(normalize_y=True),\n",
    "            Lasso(alpha=0.1),\n",
    "            SVR(kernel='rbf', C=0.0255, gamma='scale'),\n",
    "            LGBMRegressor(n_estimators=100, max_depth=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr = 0.507, MAE = 2.395 Func: SVR(C=0.0255, kernel='linear')\n",
      "Corr = 0.453, MAE = 2.892 Func: LinearSVR(C=0.0255, tol=0.001)\n",
      "Corr = 0.242, MAE = 4.993 Func: LinearRegression()\n",
      "Corr = 0.496, MAE = 2.526 Func: Ridge(alpha=200)\n",
      "Corr = 0.407, MAE = 2.624 Func: RandomForestRegressor(max_depth=24)\n",
      "Corr = 0.364, MAE = 2.663 Func: MLPRegressor(hidden_layer_sizes=(100, 50))\n",
      "Corr = 0.37, MAE = 2.59 Func: KNeighborsRegressor(n_neighbors=10)\n",
      "Corr = 0.252, MAE = 3.168 Func: DecisionTreeRegressor(max_depth=10)\n",
      "Corr = 0.261, MAE = 2.795 Func: GradientBoostingRegressor(max_depth=5)\n",
      "Corr = -0.044, MAE = 3.013 Func: GaussianProcessRegressor(normalize_y=True)\n",
      "Corr = 0.472, MAE = 2.572 Func: Lasso(alpha=0.1)\n",
      "Corr = 0.395, MAE = 2.835 Func: SVR(C=0.0255)\n",
      "Corr = 0.311, MAE = 2.788 Func: LGBMRegressor(max_depth=5)\n"
     ]
    }
   ],
   "source": [
    "for clf in clf_list:\n",
    "    get_kfold_results(clf, X,  y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
